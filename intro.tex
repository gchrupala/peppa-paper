\section{Introduction}
\label{sec:intro}

Attempts to model or simulate the acquisition of spoken language via
grounding in the visual modality date to the beginning of this century
\citep{roypentland2002learning} but have gained momentum since
2015. As noted by \citep{chrupala-visually-2021}, most current work
well enough from an applied point of view but leave much to be desired
as regards ecological validity. Most datasets consist of static images
paired with their descriptions. Existing video datasets contain spoken
descriptions of what happens in the video. The type of input that a
child faces when learning a language is much more challenging.
Firstly, speech is only loosely coupled with the visual
modality. Secondly in addition to correlations between the visual
scenes and the {\it meaning} of spoken utterances, there are also
correlations with non-semantic aspects of the speech signal, such as
the voice of specific characters and environmental noise. These
non-semantic correlations make it harder for the learner to zoom in
on those aspects of the audio signal most relevant to learning
meanings of linguistic units. 

In the current study we make a first step towards simulating such a
naturalistic grounding scenario: we use the well-know children's
cartoon {\it Peppa Pig} as a case study. Compared to commonly used
video datasets, this data features an different set of features. The
visual modality is very schematic, and the language is also simple in
terms or vocabulary size and syntactic complexity. Crucially, however,
most of the speech in the videos feature naturalistic dialogs between
the characters. The utterances are only loosely and noisily correlated
to the scenes and actions depicted in the videos. This choice of data
thus allows us to directly address the ecological limitations of the
current approaches.

We implement a model which learns to project visual scenes and spoken
utterances into a join vector space, and train it on snippets of
video containing dialog from the Peppa Pig cartoon, and carry out an
in-depth evaluating of the nature of the learned representations using
a variety of approaches.
